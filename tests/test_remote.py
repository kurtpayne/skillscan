from __future__ import annotations

from pathlib import Path
from typing import Any

from skillscan.remote import fetch_remote_target, is_url_target


class _FakeResp:
    def __init__(self, payload: str):
        self.payload = payload.encode("utf-8")

    def read(self) -> bytes:
        return self.payload

    def __enter__(self) -> _FakeResp:
        return self

    def __exit__(self, *args: Any) -> None:
        return None


def test_is_url_target() -> None:
    assert is_url_target("https://example.com/a")
    assert not is_url_target("/tmp/a")


def test_fetch_remote_target_follows_links(monkeypatch) -> None:
    pages = {
        "https://raw.githubusercontent.com/blader/humanizer/main/SKILL.md": "[src](./main.py)",
        "https://raw.githubusercontent.com/blader/humanizer/main/main.py": "print('ok')",
    }

    def fake_urlopen(req, timeout=12):
        _ = timeout
        url = req.full_url if hasattr(req, "full_url") else str(req)
        return _FakeResp(pages[url])

    monkeypatch.setattr("urllib.request.urlopen", fake_urlopen)
    res = fetch_remote_target("https://github.com/blader/humanizer/blob/main/SKILL.md?plain=1")
    files = [p.name for p in Path(res.root).iterdir()]
    assert any(name.endswith("SKILL.md") for name in files)
    assert any(name.endswith("main.py") for name in files)
    assert res.unreadable_urls == []
    assert res.skipped_urls == []
    res.cleanup_dir.cleanup()


def test_fetch_remote_target_unreadable_link(monkeypatch) -> None:
    pages = {
        "https://example.com/SKILL.md": "[src](https://example.com/missing.py)",
    }

    def fake_urlopen(req, timeout=12):
        _ = timeout
        url = req.full_url if hasattr(req, "full_url") else str(req)
        if url not in pages:
            raise ValueError("missing")
        return _FakeResp(pages[url])

    monkeypatch.setattr("urllib.request.urlopen", fake_urlopen)
    res = fetch_remote_target("https://example.com/SKILL.md")
    assert len(res.unreadable_urls) == 1
    assert res.skipped_urls == []
    res.cleanup_dir.cleanup()


def test_fetch_remote_target_same_origin_policy(monkeypatch) -> None:
    pages = {
        "https://example.com/SKILL.md": "[local](https://example.com/a.py) [x](https://other.example/b.py)",
        "https://example.com/a.py": "print('ok')",
        "https://other.example/b.py": "print('x')",
    }

    def fake_urlopen(req, timeout=12):
        _ = timeout
        url = req.full_url if hasattr(req, "full_url") else str(req)
        return _FakeResp(pages[url])

    monkeypatch.setattr("urllib.request.urlopen", fake_urlopen)
    res = fetch_remote_target("https://example.com/SKILL.md", same_origin_only=True)
    assert len(res.skipped_urls) == 1
    assert "other.example" in res.skipped_urls[0]
    res.cleanup_dir.cleanup()
