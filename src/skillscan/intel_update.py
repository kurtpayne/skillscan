from __future__ import annotations

import json
import time
import urllib.error
import urllib.request
from importlib import resources
from pathlib import Path
from typing import TypedDict

from skillscan.intel import intel_dir, upsert_source


class ManagedSource(TypedDict):
    name: str
    kind: str
    format: str
    url: str


class SyncStats(TypedDict):
    updated: int
    skipped: int
    errors: int


def _load_sources() -> list[ManagedSource]:
    raw = resources.files("skillscan.data.intel").joinpath("managed_sources.json").read_text(encoding="utf-8")
    parsed = json.loads(raw)
    if not isinstance(parsed, list):
        return []
    out: list[ManagedSource] = []
    for entry in parsed:
        if not isinstance(entry, dict):
            continue
        required = {"name", "kind", "format", "url"}
        if not required.issubset(entry.keys()):
            continue
        out.append(
            {
                "name": str(entry["name"]),
                "kind": str(entry["kind"]),
                "format": str(entry["format"]),
                "url": str(entry["url"]),
            }
        )
    return out


def _read_url(url: str, timeout_seconds: int) -> str:
    req = urllib.request.Request(url, headers={"User-Agent": "skillscan/0.1"})
    with urllib.request.urlopen(req, timeout=timeout_seconds) as resp:
        payload = resp.read()
    if isinstance(payload, str):
        return payload
    if isinstance(payload, bytes):
        return payload.decode("utf-8", errors="ignore")
    return str(payload)


def _parse_ioc_text(raw: str, source_format: str) -> dict[str, list[str]]:
    urls: set[str] = set()
    ips: set[str] = set()
    domains: set[str] = set()

    for line in raw.splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        if source_format == "url_text" and line.startswith("http"):
            urls.add(line.lower())
            continue
        if source_format == "ip_text":
            token = line.split()[0]
            if token.count(".") == 3:
                ips.add(token)
            continue
        if source_format == "domain_text":
            domains.add(line.lower())

    return {
        "domains": sorted(domains),
        "ips": sorted(ips),
        "urls": sorted(urls),
    }


def _is_stale(path: Path, max_age_seconds: int) -> bool:
    if not path.exists():
        return True
    age = time.time() - path.stat().st_mtime
    return age > max_age_seconds


def sync_managed(max_age_seconds: int = 3600, timeout_seconds: int = 3, force: bool = False) -> SyncStats:
    stats: SyncStats = {"updated": 0, "skipped": 0, "errors": 0}
    sources = _load_sources()
    for source in sources:
        if source["kind"] != "ioc":
            stats["skipped"] += 1
            continue

        target = intel_dir() / f"managed_{source['name']}.json"
        if not force and not _is_stale(target, max_age_seconds=max_age_seconds):
            upsert_source(name=f"managed:{source['name']}", kind="ioc", path=target, enabled=True)
            stats["skipped"] += 1
            continue

        try:
            raw = _read_url(source["url"], timeout_seconds=timeout_seconds)
            parsed = _parse_ioc_text(raw, source["format"])
            target.write_text(json.dumps(parsed, indent=2), encoding="utf-8")
            upsert_source(name=f"managed:{source['name']}", kind="ioc", path=target, enabled=True)
            stats["updated"] += 1
        except (OSError, urllib.error.URLError, TimeoutError, ValueError):
            stats["errors"] += 1

    return stats
